package workers

import (
	"log"
	"sync"
	"time"

	"url-shortener/models"
	"url-shortener/repository"
)

// ClickAnalyticsWorker x·ª≠ l√Ω click events b·∫•t ƒë·ªìng b·ªô
// S·ª≠ d·ª•ng Goroutines v√† Channels ƒë·ªÉ kh√¥ng l√†m ch·∫≠m request ch√≠nh
type ClickAnalyticsWorker struct {
	eventChannel  chan *models.ClickEvent
	urlRepo       *repository.URLRepositoryImpl
	analyticsRepo *repository.AnalyticsRepositoryImpl
	workerCount   int
	batchSize     int
	flushInterval time.Duration
	wg            sync.WaitGroup
	quit          chan struct{}
	isRunning     bool
	mu            sync.Mutex
}

// NewClickAnalyticsWorker t·∫°o worker m·ªõi
func NewClickAnalyticsWorker(
	urlRepo *repository.URLRepositoryImpl,
	analyticsRepo *repository.AnalyticsRepositoryImpl,
	workerCount int,
	bufferSize int,
) *ClickAnalyticsWorker {
	return &ClickAnalyticsWorker{
		eventChannel:  make(chan *models.ClickEvent, bufferSize),
		urlRepo:       urlRepo,
		analyticsRepo: analyticsRepo,
		workerCount:   workerCount,
		batchSize:     100,             // Batch 100 events
		flushInterval: 5 * time.Second, // Flush m·ªói 5 gi√¢y
		quit:          make(chan struct{}),
		isRunning:     false,
	}
}

// Start kh·ªüi ƒë·ªông worker pool
func (w *ClickAnalyticsWorker) Start() {
	w.mu.Lock()
	if w.isRunning {
		w.mu.Unlock()
		return
	}
	w.isRunning = true
	w.mu.Unlock()

	log.Printf("üöÄ Starting %d analytics workers...", w.workerCount)

	// Kh·ªüi ƒë·ªông nhi·ªÅu workers (Goroutines)
	for i := 0; i < w.workerCount; i++ {
		w.wg.Add(1)
		go w.worker(i)
	}

	log.Println("‚úÖ Analytics workers started successfully")
}

// Stop d·ª´ng t·∫•t c·∫£ workers gracefully
func (w *ClickAnalyticsWorker) Stop() {
	w.mu.Lock()
	if !w.isRunning {
		w.mu.Unlock()
		return
	}
	w.mu.Unlock()

	log.Println("üõë Stopping analytics workers...")

	// ƒê√≥ng quit channel ƒë·ªÉ signal stop
	close(w.quit)

	// ƒê·ª£i t·∫•t c·∫£ workers ho√†n th√†nh
	w.wg.Wait()

	// ƒê√≥ng event channel
	close(w.eventChannel)

	w.mu.Lock()
	w.isRunning = false
	w.mu.Unlock()

	log.Println("‚úÖ Analytics workers stopped")
}

// Enqueue th√™m event v√†o queue (non-blocking)
func (w *ClickAnalyticsWorker) Enqueue(event *models.ClickEvent) {
	// Non-blocking send v·ªõi select
	select {
	case w.eventChannel <- event:
		// Event ƒë∆∞·ª£c enqueue th√†nh c√¥ng
	default:
		// Channel ƒë·∫ßy, log warning nh∆∞ng kh√¥ng block
		log.Printf("‚ö†Ô∏è Analytics queue full, dropping event for: %s", event.ShortCode)
	}
}

// worker x·ª≠ l√Ω events t·ª´ channel
func (w *ClickAnalyticsWorker) worker(id int) {
	defer w.wg.Done()

	log.Printf("Worker %d started", id)

	batch := make([]*models.ClickEvent, 0, w.batchSize)
	ticker := time.NewTicker(w.flushInterval)
	defer ticker.Stop()

	for {
		select {
		case <-w.quit:
			// Flush remaining batch tr∆∞·ªõc khi tho√°t
			if len(batch) > 0 {
				w.processBatch(batch, id)
			}
			log.Printf("Worker %d stopped", id)
			return

		case event := <-w.eventChannel:
			if event == nil {
				continue
			}

			batch = append(batch, event)

			// Flush khi batch ƒë·∫ßy
			if len(batch) >= w.batchSize {
				w.processBatch(batch, id)
				batch = make([]*models.ClickEvent, 0, w.batchSize)
			}

		case <-ticker.C:
			// Flush theo interval
			if len(batch) > 0 {
				w.processBatch(batch, id)
				batch = make([]*models.ClickEvent, 0, w.batchSize)
			}
		}
	}
}

// processBatch x·ª≠ l√Ω m·ªôt batch events
func (w *ClickAnalyticsWorker) processBatch(batch []*models.ClickEvent, workerID int) {
	if len(batch) == 0 {
		return
	}

	start := time.Now()
	successCount := 0
	errorCount := 0

	// Group events theo short_code ƒë·ªÉ update click count hi·ªáu qu·∫£
	clickCounts := make(map[string]int)

	for _, event := range batch {
		// L∆∞u click event v√†o database
		if err := w.analyticsRepo.SaveClickEvent(event); err != nil {
			log.Printf("Error saving click event: %v", err)
			errorCount++
			continue
		}

		successCount++
		clickCounts[event.ShortCode]++
	}

	// Batch update click counts
	for shortCode, count := range clickCounts {
		for i := 0; i < count; i++ {
			if err := w.urlRepo.IncrementClickCount(shortCode); err != nil {
				log.Printf("Error incrementing click count for %s: %v", shortCode, err)
			}
		}
	}

	elapsed := time.Since(start)
	log.Printf("Worker %d: Processed batch of %d events (%d success, %d errors) in %v",
		workerID, len(batch), successCount, errorCount, elapsed)
}

// GetQueueSize tr·∫£ v·ªÅ s·ªë events ƒëang ch·ªù trong queue
func (w *ClickAnalyticsWorker) GetQueueSize() int {
	return len(w.eventChannel)
}

// GetStats tr·∫£ v·ªÅ th·ªëng k√™ c·ªßa worker
func (w *ClickAnalyticsWorker) GetStats() map[string]interface{} {
	return map[string]interface{}{
		"queue_size":     w.GetQueueSize(),
		"worker_count":   w.workerCount,
		"batch_size":     w.batchSize,
		"flush_interval": w.flushInterval.String(),
		"is_running":     w.isRunning,
	}
}
